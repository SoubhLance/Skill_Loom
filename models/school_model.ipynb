{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns after renaming: ['stream', 'skills', 'jobs_opportunities', 'workshops_competitions']\n",
      "Top Recommendations for Student:\n",
      "     stream           jobs_opportunities   workshops_competitions  \\\n",
      "5      Arts  Junior Data Entry Assistant  Photography Competition   \n",
      "19     Arts            Creative Designer         School Hackathon   \n",
      "39     Arts         School Web Developer  Photography Competition   \n",
      "1   Science   Student Research Assistant        Robotics Workshop   \n",
      "3   Science   Student Research Assistant             Science Fair   \n",
      "\n",
      "    similarity_score   missing_skills  \n",
      "5           0.639493           [html]  \n",
      "19          0.639493           [html]  \n",
      "39          0.639493           [html]  \n",
      "1           0.506984  [math modeling]  \n",
      "3           0.506984  [math modeling]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Data\n",
    "# -----------------------------\n",
    "df = pd.read_excel(\"school_dataset.xlsx\")\n",
    "\n",
    "# Normalize column names to lowercase and underscores\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"/\", \"_\")\n",
    "\n",
    "print(\"Available columns after renaming:\", df.columns.tolist())\n",
    "# Expected: ['stream', 'skills', 'jobs_opportunities', 'workshops_competitions']\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Preprocessing\n",
    "# -----------------------------\n",
    "text_columns = [\"skills\", \"jobs_opportunities\", \"workshops_competitions\"]\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str).fillna(\"\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Feature Engineering\n",
    "# -----------------------------\n",
    "# Normalize skills text\n",
    "df[\"skills_normalized\"] = df[\"skills\"].str.lower()\n",
    "\n",
    "# TF-IDF vectorizer on skills\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"skills_normalized\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Recommendation Function\n",
    "# -----------------------------\n",
    "def get_missing_skills(user_skills, required_skills):\n",
    "    user_set = set(user_skills.lower().split(\", \"))\n",
    "    required_set = set(required_skills.lower().split(\", \"))\n",
    "    return list(required_set - user_set)\n",
    "\n",
    "def recommend_for_student(user_input_skills, top_n=5):\n",
    "    user_skills = user_input_skills.lower()\n",
    "    user_vector = vectorizer.transform([user_skills])\n",
    "\n",
    "    # Similarity score\n",
    "    cosine_similarities = cosine_similarity(user_vector, tfidf_matrix).flatten()\n",
    "    df[\"similarity_score\"] = cosine_similarities\n",
    "\n",
    "    # Final ranking\n",
    "    top_matches = df.sort_values(by=\"similarity_score\", ascending=False).head(top_n).copy()\n",
    "    top_matches[\"missing_skills\"] = top_matches[\"skills\"].apply(lambda x: get_missing_skills(user_skills, x))\n",
    "\n",
    "    return top_matches[[\"stream\", \"jobs_opportunities\", \"workshops_competitions\", \"similarity_score\", \"missing_skills\"]]\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Example Usage\n",
    "# -----------------------------\n",
    "user_input_skills = \"Python, Problem Solving\"\n",
    "recommendations = recommend_for_student(user_input_skills, top_n=5)\n",
    "\n",
    "print(\"Top Recommendations for Student:\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stream', 'skills', 'jobs_opportunities', 'workshops_competitions', 'skills_normalized', 'similarity_score']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns after renaming: ['stream', 'skills', 'jobs_opportunities', 'workshops_competitions']\n",
      "\n",
      "✅ Top Recommendations for Student:\n",
      "     stream           jobs_opportunities   workshops_competitions  \\\n",
      "5      Arts  Junior Data Entry Assistant  Photography Competition   \n",
      "19     Arts            Creative Designer         School Hackathon   \n",
      "39     Arts         School Web Developer  Photography Competition   \n",
      "1   Science   Student Research Assistant        Robotics Workshop   \n",
      "3   Science   Student Research Assistant             Science Fair   \n",
      "\n",
      "    final_similarity             missing_skills  \\\n",
      "5           1.000000                    [html,]   \n",
      "19          1.000000                    [html,]   \n",
      "39          1.000000                    [html,]   \n",
      "1           0.324212  [modeling, python,, math]   \n",
      "3           0.324212  [modeling, python,, math]   \n",
      "\n",
      "                              unseen_input_skills  \n",
      "5   [leadership, communication, quantumcomputing]  \n",
      "19  [leadership, communication, quantumcomputing]  \n",
      "39  [leadership, communication, quantumcomputing]  \n",
      "1   [leadership, communication, quantumcomputing]  \n",
      "3   [leadership, communication, quantumcomputing]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load Dataset\n",
    "# -----------------------------\n",
    "df = pd.read_excel(\"school_dataset.xlsx\")\n",
    "\n",
    "# Standardize column names\n",
    "df.columns = df.columns.str.strip().str.title()\n",
    "df.rename(columns={\n",
    "    \"Stream\": \"stream\",\n",
    "    \"Skills\": \"skills\",\n",
    "    \"Jobs/Opportunities\": \"jobs_opportunities\",\n",
    "    \"Workshops/Competitions\": \"workshops_competitions\"\n",
    "}, inplace=True)\n",
    "\n",
    "print(\"Available columns after renaming:\", df.columns.tolist())\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Preprocessing\n",
    "# -----------------------------\n",
    "text_columns = [\"skills\", \"jobs_opportunities\", \"workshops_competitions\"]\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str).fillna(\"\")\n",
    "\n",
    "# Normalize skills\n",
    "df[\"skills_normalized\"] = df[\"skills\"].str.lower().str.replace(r\"[^a-zA-Z0-9, ]\", \"\", regex=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Vectorization (TF-IDF)\n",
    "# -----------------------------\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"skills_normalized\"])\n",
    "dataset_vocab = set(vectorizer.get_feature_names_out())  # vocabulary of dataset skills\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Similarity Function\n",
    "# -----------------------------\n",
    "def get_missing_skills(user_skills, dataset_skills):\n",
    "    return list(set(dataset_skills) - set(user_skills))\n",
    "\n",
    "def recommend_for_student(user_input, top_n=5):\n",
    "    # Clean and split user input\n",
    "    user_input_cleaned = user_input.lower().replace(\",\", \" \")\n",
    "    user_skills = set(user_input_cleaned.split())\n",
    "\n",
    "    # Identify seen vs unseen skills\n",
    "    seen_skills = user_skills.intersection(dataset_vocab)\n",
    "    unseen_skills = user_skills - dataset_vocab\n",
    "\n",
    "    # Encode seen skills\n",
    "    user_vector = vectorizer.transform([\" \".join(seen_skills)])\n",
    "    similarity_scores = cosine_similarity(user_vector, tfidf_matrix).flatten()\n",
    "    df[\"similarity_score_tfidf\"] = similarity_scores\n",
    "    df[\"final_similarity\"] = df[\"similarity_score_tfidf\"]\n",
    "\n",
    "    # Case 1: No overlap at all\n",
    "    if len(seen_skills) == 0:\n",
    "        print(\"\\n⚠️ None of the input skills were found in the dataset.\")\n",
    "        fallback = pd.DataFrame({\n",
    "            \"stream\": [\"General\", \"General\", \"General\"],\n",
    "            \"jobs_opportunities\": [\n",
    "                \"Internships in Emerging Tech (AI, IoT, AR/VR)\",\n",
    "                \"General Research Internships\",\n",
    "                \"Community Volunteering / Leadership Roles\"\n",
    "            ],\n",
    "            \"workshops_competitions\": [\n",
    "                \"Soft Skills & Communication Workshop\",\n",
    "                \"Entrepreneurship & Innovation Bootcamp\",\n",
    "                \"Hackathons / Ideathons (Open to All)\"\n",
    "            ],\n",
    "            \"final_similarity\": [0, 0, 0],\n",
    "            \"missing_skills\": [[\"Add skills to dataset\"], [\"Add skills to dataset\"], [\"Add skills to dataset\"]],\n",
    "            \"unseen_input_skills\": [list(unseen_skills)] * 3\n",
    "        })\n",
    "        return fallback\n",
    "\n",
    "    # Case 2: Partial match (some seen, some unseen)\n",
    "    top_matches = df.sort_values(by=\"final_similarity\", ascending=False).head(top_n).copy()\n",
    "    top_matches[\"missing_skills\"] = top_matches[\"skills_normalized\"].apply(lambda x: get_missing_skills(seen_skills, x.split()))\n",
    "    top_matches[\"unseen_input_skills\"] = [list(unseen_skills)] * len(top_matches)\n",
    "\n",
    "    return top_matches[[\"stream\", \"jobs_opportunities\", \"workshops_competitions\", \"final_similarity\", \"missing_skills\", \"unseen_input_skills\"]]\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Example Usage\n",
    "# -----------------------------\n",
    "user_input_skills = \"Python, HTML, Communication, QuantumComputing, Leadership\"\n",
    "recommendations = recommend_for_student(user_input_skills, top_n=5)\n",
    "\n",
    "print(\"\\n✅ Top Recommendations for Student:\")\n",
    "print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\models_skillloom\\Skill-Loom\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: <class 'sentence_transformers.SentenceTransformer.SentenceTransformer'>\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "\n",
    "# Define model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Save model with pickle\n",
    "with open(\"school.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Load model back\n",
    "with open(\"school.pkl\", \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "print(\"Model loaded:\", type(loaded_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
